---
title: 'Preprocessing: raw to processed data'
author: "Marton Kovacs"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)

# Source R scripts
r_scripts <- list.files(here::here("R/"), full.names = TRUE)
purrr::walk(r_scripts, source)
```

## Loading data

```{r}
# Load rating responses
raw <- read_csv(here("data/raw/sse_raw_data.csv"))

# Load form metadata
metadata <- read_csv(here("data/raw/sse_form_data.csv"))
```

## Filtering responses

```{r}
raw <- 
  raw %>% 
  # Deleting not finished responses
  filter(finished == TRUE) %>% 
  # RTT ratings were part of a test, they will be dropped
  filter(rater_id != "RTT") %>% 
  # Dropping other pilot responses
  filter(response_id %ni% c("R_2bWBnJT0Cw8Qgaz", "R_1MKUba6zqHTN9FO", "R_2S61dRpE4lcYdLf", "R_27rJ05z0nVx9Egd", "	
R_3njivFsE7lY07Xa", "R_3njivFsE7lY07Xa"))
```

## Adding missing form ids

The `form_id` question was added to the survey after the rating process has been started. We will now add missing values to the `form_id` variable.

```{r}
raw <-
  raw %>% 
  mutate(
    form_id = if_else(
      # For these ratings the form_id was recorded in the name_org variable
      response_id %in% c(
        "R_2dNpO7fG8PTkJDS", "R_3OdnkFkKnzkTqET", "R_z6UHBRQji7688tr", "R_2vign84BhCDlbog", "R_1DJ5ejXFUoL1rjZ", "R_2TNqVplrbcPjMIs", "R_27vbmE6D63WCzeT", "R_2P7DC1sQGNTY2JE", "R_AbLXV5GKCNaCytz" ),
      name_org,
      form_id),
    # For the rest we have to do manual assignment
    form_id = case_when(
      response_id == "R_21HcPShrkjQ3Lxc" ~ "washington_01",
      response_id == "R_1laxNOQf3CZ7zJg" ~ "washington_02",
      response_id == "R_2SBxumkkJTJnvyo" ~ "stanford_01",
      response_id == "R_32Jg75n3pxZnDtE" ~ "stanford_02",
      response_id == "R_1FRpbrCPndt1dN8" ~ "maryland_01",
      response_id == "R_3hn1u7TIpTJoZv7" ~ "hopkins_01",
      TRUE ~ form_id
    )
  )
```

## Selecting variables

```{r}
raw <-
  raw %>% 
  # Variables that are added by Qualtrics but do not have any useful information in terms of the study
  select(-empty_col, -status, -finished, -recipient_last_name, -recipient_first_name, -recipient_email, -external_reference, -location_latitude, -location_longitude, -distribution_channel, -user_language, -progress, -start_date, -end_date) %>% 
  # Variables that were manually rated originally but will be replaced by program code
  select(-country, -origin_org, -name_org, -rank_org, -risk_level_text)
```

## Preparing data for rating comparison

The two raters MK and SP will compare their ratings. For this task, we are preparing a rating table.

```{r}
rating <-
  raw %>% 
  select(-duration_in_seconds, -recorded_date, -response_id) %>% 
  pivot_longer(
    !c("form_id", "rater_id"),
    names_to = "variable",
    values_to = "rating"
  ) %>% 
  pivot_wider(
    id_cols = c("form_id", "variable"),
    names_from = rater_id,
    values_from = rating,
    names_glue = "{rater_id}_rating"
  ) %>% 
  arrange(form_id) %>%
  janitor::clean_names() %>% 
  mutate(
    final_rating = NA_character_
  )
```

Filtering forms where both ratings are present for comparison and saving the dataset.

```{r}
rating %>% 
  filter(if_all(c("sp_rating", "mk_rating"), ~ !is.na(.))) %>% 
  write_csv(., here("data/raw/raw_comparison_data.csv"))
```

## Merging metadata

Metadata about the forms were collected separately. We now join the metadata with the rating responses.

```{r}
raw <-
  raw %>% 
  left_join(., form_data, by = "form_id")
```

## Testing

We test the dataset for completeness and to find any possible coding errors.

```{r}
# Test for uniqueness of form_id per rater
raw %>% 
  group_by(rater_id, form_id) %>% 
  count() %>% 
  filter(n != 1)
```

